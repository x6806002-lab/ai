# -*- coding: utf-8 -*-
"""
ä¸“å®¶æ‰“åˆ†ç³»ç»Ÿ - å®Œæ•´çš„æ•°æ®å­˜å‚¨ä¸ä¸€è‡´æ€§éªŒè¯
æ”¯æŒå¤šä½ä¸“å®¶æ•°æ®æŒä¹…åŒ–å­˜å‚¨ã€ä¸€è‡´æ€§éªŒè¯å’Œæƒé‡è®¡ç®—
ä¸€é”®è¿è¡Œï¼šstreamlit run D:\Project\test1.1.py
"""

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
import hashlib
from typing import List, Dict, Tuple, Any
import itertools
from datetime import datetime
import matplotlib

matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Heiti SC', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="ä¸“å®¶æ‰“åˆ†ç³»ç»Ÿ - AHPæƒé‡è®¡ç®—",
    page_icon="ğŸ‘¨â€ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åº”ç”¨æ ‡é¢˜
st.title("ğŸ‘¨â€ğŸ“ ä¸“å®¶æ‰“åˆ†ç³»ç»Ÿ - AHPä¸€è‡´æ€§éªŒè¯ä¸æƒé‡è®¡ç®—")
st.markdown("""
### å¤§å­¦ç”Ÿäººå·¥æ™ºèƒ½æ•°æ®ç´ å…»è¯„ä»·ä½“ç³»ä¸“å®¶æƒé‡ç¡®å®š
æ”¯æŒå¤šåä¸“å®¶ç‹¬ç«‹æ‰“åˆ†ï¼Œæ•°æ®æŒä¹…åŒ–å­˜å‚¨ï¼Œè‡ªåŠ¨è¿›è¡Œä¸€è‡´æ€§éªŒè¯å’Œæƒé‡è®¡ç®—
""")


class ExpertDataManager:
    """ä¸“å®¶æ•°æ®ç®¡ç†å™¨ - è´Ÿè´£æ•°æ®çš„æŒä¹…åŒ–å­˜å‚¨"""

    def __init__(self, data_file="expert_data.json"):
        self.data_file = data_file
        self.ensure_data_file()

    def ensure_data_file(self):
        """ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨"""
        if not os.path.exists(self.data_file):
            # åˆ›å»ºç©ºçš„ä¸“å®¶æ•°æ®ç»“æ„
            initial_data = {
                "experts": {},
                "projects": {},
                "analysis_sessions": {},
                "metadata": {
                    "created_time": datetime.now().isoformat(),
                    "last_modified": datetime.now().isoformat(),
                    "version": "1.0"
                }
            }
            self.save_data(initial_data)

    def load_data(self):
        """åŠ è½½ä¸“å®¶æ•°æ®"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            # å¦‚æœæ–‡ä»¶æŸåæˆ–ä¸å­˜åœ¨ï¼Œé‡æ–°åˆå§‹åŒ–
            self.ensure_data_file()
            return self.load_data()

    def save_data(self, data):
        """ä¿å­˜ä¸“å®¶æ•°æ®"""
        try:
            # æ›´æ–°å…ƒæ•°æ®
            data["metadata"]["last_modified"] = datetime.now().isoformat()
            data["metadata"]["total_experts"] = len(data["experts"])

            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            st.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False

    def generate_expert_id(self, expert_info):
        """ç”Ÿæˆä¸“å®¶å”¯ä¸€ID"""
        identifier = f"{expert_info['id']}_{expert_info['name']}_{expert_info['institution']}"
        return hashlib.md5(identifier.encode()).hexdigest()[:12]

    def register_expert(self, expert_info):
        """æ³¨å†Œä¸“å®¶"""
        data = self.load_data()
        expert_id = self.generate_expert_id(expert_info)

        if expert_id in data["experts"]:
            return False, "è¯¥ä¸“å®¶å·²æ³¨å†Œ"

        # æ·»åŠ æ³¨å†Œæ—¶é—´
        expert_info["registration_time"] = datetime.now().isoformat()
        expert_info["expert_id"] = expert_id
        expert_info["judgment_matrices"] = {}
        expert_info["consistency_checks"] = {}
        expert_info["active"] = True

        data["experts"][expert_id] = expert_info

        if self.save_data(data):
            return True, expert_id
        else:
            return False, "æ³¨å†Œå¤±è´¥"

    def update_expert_judgment(self, expert_id, level, judgment_matrix, weights, cr):
        """æ›´æ–°ä¸“å®¶åˆ¤æ–­æ•°æ®"""
        data = self.load_data()

        if expert_id not in data["experts"]:
            return False

        # ä¿å­˜åˆ¤æ–­çŸ©é˜µå’Œä¸€è‡´æ€§ç»“æœ
        data["experts"][expert_id]["judgment_matrices"][level] = {
            "matrix": judgment_matrix.tolist() if hasattr(judgment_matrix, 'tolist') else judgment_matrix,
            "saved_time": datetime.now().isoformat()
        }

        data["experts"][expert_id]["consistency_checks"][level] = {
            "weights": weights.tolist() if hasattr(weights, 'tolist') else weights,
            "consistency_ratio": cr,
            "check_time": datetime.now().isoformat(),
            "status": "excellent" if cr < 0.1 else "acceptable" if cr < 0.2 else "unacceptable"
        }

        return self.save_data(data)

    def get_all_experts(self):
        """è·å–æ‰€æœ‰ä¸“å®¶"""
        data = self.load_data()
        return data["experts"]

    def get_expert_judgments(self, level):
        """è·å–æŒ‡å®šå±‚æ¬¡çš„æ‰€æœ‰ä¸“å®¶åˆ¤æ–­æ•°æ®"""
        data = self.load_data()
        judgments = {}

        for expert_id, expert_data in data["experts"].items():
            if level in expert_data["judgment_matrices"] and level in expert_data["consistency_checks"]:
                judgments[expert_id] = {
                    "expert_info": {k: v for k, v in expert_data.items() if
                                    k not in ["judgment_matrices", "consistency_checks"]},
                    "matrix": np.array(expert_data["judgment_matrices"][level]["matrix"]),
                    "weights": np.array(expert_data["consistency_checks"][level]["weights"]),
                    "cr": expert_data["consistency_checks"][level]["consistency_ratio"],
                    "status": expert_data["consistency_checks"][level]["status"]
                }

        return judgments

    def create_analysis_session(self, session_name, description, levels_analyzed):
        """åˆ›å»ºåˆ†æä¼šè¯"""
        data = self.load_data()

        session_id = hashlib.md5(f"{session_name}_{datetime.now().isoformat()}".encode()).hexdigest()[:8]

        data["analysis_sessions"][session_id] = {
            "session_name": session_name,
            "description": description,
            "levels_analyzed": levels_analyzed,
            "created_time": datetime.now().isoformat(),
            "expert_count": len(data["experts"]),
            "results": {}
        }

        if self.save_data(data):
            return session_id
        return None

    def save_analysis_results(self, session_id, level, group_weights, analysis_details):
        """ä¿å­˜åˆ†æç»“æœ"""
        data = self.load_data()

        if session_id in data["analysis_sessions"]:
            data["analysis_sessions"][session_id]["results"][level] = {
                "group_weights": group_weights.tolist() if hasattr(group_weights, 'tolist') else group_weights,
                "analysis_details": analysis_details,
                "analysis_time": datetime.now().isoformat()
            }
            return self.save_data(data)
        return False

    def get_data_statistics(self):
        """è·å–æ•°æ®ç»Ÿè®¡"""
        data = self.load_data()
        stats = {
            "total_experts": len(data["experts"]),
            "active_experts": len([e for e in data["experts"].values() if e.get("active", True)]),
            "analysis_sessions": len(data["analysis_sessions"]),
            "last_modified": data["metadata"]["last_modified"]
        }

        # è®¡ç®—å„å±‚æ¬¡çš„åˆ†æå®Œæˆæƒ…å†µ
        levels = ["ä¸€çº§æŒ‡æ ‡"] + list(ExpertDataManager.get_evaluation_system()["äºŒçº§æŒ‡æ ‡"].keys())
        level_stats = {}

        for level in levels:
            judgments = self.get_expert_judgments(level)
            level_stats[level] = {
                "completed_experts": len(judgments),
                "acceptable_judgments": len([j for j in judgments.values() if j["cr"] < 0.2])
            }

        stats["level_completion"] = level_stats
        return stats

    @staticmethod
    def get_evaluation_system():
        """è·å–è¯„ä»·ä½“ç³»ç»“æ„"""
        return {
            "ä¸€çº§æŒ‡æ ‡": [
                "B1: ç³»ç»Ÿæ€§è®¤çŸ¥",
                "B2: æ„å»ºå¼èƒ½åŠ›",
                "B3: åˆ›é€ ä¸æ€è¾¨",
                "B4: äººæœ¬ä¸è´£ä»»"
            ],
            "äºŒçº§æŒ‡æ ‡": {
                "B1: ç³»ç»Ÿæ€§è®¤çŸ¥": [
                    "C11: æ•°æ®ä¸çŸ¥è¯†",
                    "C12: ç®—æ³•ä¸æ¨¡å‹",
                    "C13: ç®—åŠ›ä¸ç³»ç»Ÿ",
                    "C14: äº¤å‰ä¸åº”ç”¨",
                    "C15: å¯ä¿¡ä¸å®‰å…¨"
                ],
                "B2: æ„å»ºå¼èƒ½åŠ›": [
                    "C21: é—®é¢˜æŠ½è±¡ä¸å®šä¹‰",
                    "C22: åˆ†è§£ä¸æ¨¡å—åŒ–",
                    "C23: å·¥å…·é€‰æ‹©ä¸æ¨¡å‹æ„å»º",
                    "C24: éªŒè¯ã€è¯„ä¼°ä¸è¿­ä»£",
                    "C25: ç»“æœè§£é‡Šä¸æ²Ÿé€š"
                ],
                "B3: åˆ›é€ ä¸æ€è¾¨": [
                    "C31: è·¨æƒ…å¢ƒè¿ç§»ä¸åº”ç”¨",
                    "C32: äº‹å®æ ¸æŸ¥ä¸é€»è¾‘æ‰¹åˆ¤",
                    "C33: è‡ªä¸»è§„åˆ’ä¸ä¸ªæ€§åŒ–å­¦ä¹ ",
                    "C34: ä¸»åŠ¨æ¢ç´¢ä¸åˆ›é€ ",
                    "C35: å­¦ä¹ è¿‡ç¨‹åæ€ä¸å…ƒè®¤çŸ¥"
                ],
                "B4: äººæœ¬ä¸è´£ä»»": [
                    "C41: æ•°æ®å®‰å…¨ä¸éšç§ä¿æŠ¤",
                    "C42: ç®—æ³•åå·®ä¸æ¨¡å‹å¹»è§‰",
                    "C43: AIå‘å–„å’Œä»¥äººä¸ºæœ¬",
                    "C44: äººæœºååŒçš„è´£ä»»ç•Œå®š",
                    "C45: çŸ¥è¯†æ™®æƒ ä¸ç¤¾ä¼šå…¬å¹³"
                ]
            }
        }


class AHPExpertScoringSystem:
    """AHPä¸“å®¶æ‰“åˆ†ç³»ç»Ÿ"""

    def show_historical_data_viewer(self):
        """æ˜¾ç¤ºå†å²æ•°æ®æŸ¥çœ‹å™¨"""
        st.sidebar.header("ğŸ“‹ å†å²æ•°æ®æŸ¥çœ‹")

        if not st.session_state.current_expert_id:
            st.sidebar.info("è¯·å…ˆæ³¨å†Œæˆ–é€‰æ‹©ä¸“å®¶")
            return

        expert_data = self.data_manager.load_data()
        expert_info = expert_data["experts"].get(st.session_state.current_expert_id, {})

        if not expert_info.get("judgment_matrices"):
            st.sidebar.info("æš‚æ— å†å²æ‰“åˆ†æ•°æ®")
            return

        # æ˜¾ç¤ºæœ‰æ•°æ®çš„å±‚æ¬¡
        levels_with_data = list(expert_info["judgment_matrices"].keys())
        selected_level = st.sidebar.selectbox(
            "é€‰æ‹©æŸ¥çœ‹å±‚æ¬¡",
            levels_with_data
        )

        if selected_level and st.sidebar.button("æŸ¥çœ‹è¯¦ç»†æ•°æ®"):
            # åœ¨ä¸»ç•Œé¢æ˜¾ç¤ºè¯¦ç»†å†å²æ•°æ®
            st.header(f"ğŸ“‹ {selected_level} - å†å²æ‰“åˆ†è¯¦æƒ…")

            # è·å–å†å²æ•°æ®
            historical_data = expert_info["judgment_matrices"][selected_level]
            consistency_data = expert_info["consistency_checks"][selected_level]

            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            col1.metric("ä¿å­˜æ—¶é—´", historical_data["saved_time"][:19])
            col2.metric("ä¸€è‡´æ€§æ¯”ç‡", f"{consistency_data['consistency_ratio']:.4f}")
            col3.metric("çŠ¶æ€", consistency_data["status"])

            # æ˜¾ç¤ºåˆ¤æ–­çŸ©é˜µ
            st.subheader("ğŸ” å†å²åˆ¤æ–­çŸ©é˜µ")
            criteria = self.evaluation_system[selected_level] if selected_level == "ä¸€çº§æŒ‡æ ‡" else \
            self.evaluation_system["äºŒçº§æŒ‡æ ‡"][selected_level]

            matrix = np.array(historical_data["matrix"])
            display_df = pd.DataFrame(
                matrix,
                index=criteria,
                columns=criteria
            )

            # æ ¼å¼åŒ–æ˜¾ç¤º
            def format_value(x):
                if x == 1:
                    return "1.00"
                elif x > 1:
                    return f"{x:.2f}"
                else:
                    return f"1/{int(1 / x)}.{str(int(1 / x) % 100):02d}" if 1 / x < 1 else f"{1 / x:.2f}"

            formatted_df = display_df.copy()
            for col in formatted_df.columns:
                formatted_df[col] = formatted_df[col].apply(format_value)

            st.dataframe(formatted_df, use_container_width=True)

            # æ˜¾ç¤ºæƒé‡ç»“æœ
            st.subheader("ğŸ“Š å†å²æƒé‡ç»“æœ")
            weights = np.array(consistency_data["weights"])

            weight_data = []
            for i, criterion in enumerate(criteria):
                weight_data.append({
                    'æŒ‡æ ‡': criterion,
                    'æƒé‡': weights[i],
                    'æƒé‡ç™¾åˆ†æ¯”': f"{weights[i] * 100:.2f}%"
                })

            weight_df = pd.DataFrame(weight_data)
            weight_df = weight_df.sort_values('æƒé‡', ascending=False)
            st.dataframe(weight_df, use_container_width=True)

            # å¯è§†åŒ–
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.bar(range(len(weights)), weights, color='lightblue', alpha=0.7)
            ax.set_xlabel('æŒ‡æ ‡')
            ax.set_ylabel('æƒé‡')
            ax.set_title(f'{selected_level}å†å²æƒé‡åˆ†å¸ƒ')
            ax.set_xticks(range(len(weights)))
            ax.set_xticklabels([c[:15] + "..." if len(c) > 15 else c for c in criteria], rotation=45, ha='right')

            for bar, weight in zip(bars, weights):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                        f'{weight:.3f}', ha='center', va='bottom')

            plt.tight_layout()
            st.pyplot(fig)

    def __init__(self):
        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        self.data_manager = ExpertDataManager()

        # AHPæ ‡åº¦å«ä¹‰ï¼ˆåŒ…å«å€’æ•°å…³ç³»çš„å®Œæ•´è¯´æ˜ï¼‰
        self.scale_meanings = {
            1: "åŒç­‰é‡è¦",
            2: "ç¨å¾®é‡è¦",
            3: "æ˜æ˜¾é‡è¦",
            4: "å¼ºçƒˆé‡è¦",
            5: "æç«¯é‡è¦",
            1 / 2: "ç¨å¾®ä¸é‡è¦",
            1 / 3: "æ˜æ˜¾ä¸é‡è¦",
            1 / 4: "å¼ºçƒˆä¸é‡è¦",
            1 / 5: "æç«¯ä¸é‡è¦"
        }

        # å®Œæ•´çš„AHPæ ‡åº¦é€‰é¡¹ï¼ˆåŒ…å«å€’æ•°ï¼‰
        self.ahp_scales = [1 / 5, 1 / 4, 1 / 3, 1 / 2, 1, 2, 3, 4, 5]

        # éšæœºä¸€è‡´æ€§æŒ‡æ ‡RIå€¼
        self.ri_values = {
            1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12,
            6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49
        }

        # è¯„ä»·ä½“ç³»
        self.evaluation_system = ExpertDataManager.get_evaluation_system()

    def initialize_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if 'current_expert_id' not in st.session_state:
            st.session_state.current_expert_id = None
        if 'analysis_completed' not in st.session_state:
            st.session_state.analysis_completed = False
        if 'current_level' not in st.session_state:
            st.session_state.current_level = "ä¸€çº§æŒ‡æ ‡"
        if 'current_session_id' not in st.session_state:
            st.session_state.current_session_id = None

    def create_expert_registration(self):
        """åˆ›å»ºä¸“å®¶æ³¨å†Œç•Œé¢"""
        st.sidebar.header("ğŸ‘¨â€ğŸ’¼ ä¸“å®¶æ³¨å†Œ")

        with st.sidebar.form("expert_registration"):
            st.subheader("ä¸“å®¶ä¿¡æ¯ç™»è®°")
            expert_name = st.text_input("ä¸“å®¶å§“å", placeholder="è¯·è¾“å…¥çœŸå®å§“å")
            expert_id = st.text_input("ä¸“å®¶ç¼–å·", placeholder="æœºæ„æˆ–ç³»ç»Ÿåˆ†é…ç¼–å·")
            institution = st.text_input("å·¥ä½œå•ä½", placeholder="æ‰€åœ¨é«˜æ ¡æˆ–æœºæ„")
            title = st.selectbox("èŒç§°", ["æ•™æˆ", "å‰¯æ•™æˆ", "ç ”ç©¶å‘˜", "å‰¯ç ”ç©¶å‘˜", "å…¶ä»–"])
            domain = st.selectbox("ç ”ç©¶é¢†åŸŸ", [
                "æ•™è‚²æŠ€æœ¯", "æ•°æ®ç§‘å­¦", "å¿ƒç†å­¦", "ç»Ÿè®¡å­¦",
                "ä¿¡æ¯ç®¡ç†", "è®¡ç®—æœºç§‘å­¦", "å…¶ä»–"
            ])
            experience = st.slider("ç›¸å…³é¢†åŸŸç»éªŒå¹´é™", 1, 40, 10)

            submitted = st.form_submit_button("æ³¨å†Œä¸“å®¶èº«ä»½")

            if submitted:
                if expert_name and expert_id:
                    expert_info = {
                        "name": expert_name,
                        "id": expert_id,
                        "institution": institution,
                        "title": title,
                        "domain": domain,
                        "experience": experience
                    }

                    success, result = self.data_manager.register_expert(expert_info)
                    if success:
                        st.session_state.current_expert_id = result
                        st.sidebar.success(f"æ¬¢è¿ {expert_name} ä¸“å®¶ï¼æ³¨å†ŒæˆåŠŸã€‚")
                    else:
                        st.sidebar.error(result)
                else:
                    st.sidebar.error("è¯·å¡«å†™ä¸“å®¶å§“åå’Œç¼–å·")

    def show_expert_management(self):
        """æ˜¾ç¤ºä¸“å®¶ç®¡ç†ç•Œé¢"""
        st.sidebar.header("ğŸ‘¥ ä¸“å®¶ç®¡ç†")

        experts = self.data_manager.get_all_experts()
        if experts:
            expert_list = list(experts.keys())
            expert_display_names = [f"{exp['name']} ({exp['institution']})" for exp in experts.values()]

            selected_expert = st.sidebar.selectbox(
                "é€‰æ‹©ä¸“å®¶",
                expert_display_names,
                index=0
            )

            if st.sidebar.button("åˆ‡æ¢ä¸“å®¶"):
                # æ‰¾åˆ°å¯¹åº”çš„ä¸“å®¶ID
                selected_index = expert_display_names.index(selected_expert)
                st.session_state.current_expert_id = expert_list[selected_index]

            # æ˜¾ç¤ºå½“å‰ä¸“å®¶ä¿¡æ¯
            if st.session_state.current_expert_id and st.session_state.current_expert_id in experts:
                expert_info = experts[st.session_state.current_expert_id]
                st.sidebar.markdown(f"""
                **å½“å‰ä¸“å®¶**: {expert_info['name']}
                **å•ä½**: {expert_info['institution']}
                **é¢†åŸŸ**: {expert_info['domain']}
                **ç»éªŒ**: {expert_info['experience']}å¹´
                **æ³¨å†Œæ—¶é—´**: {expert_info['registration_time'][:10]}
                """)

        # æ•°æ®æ˜¾ç¤º
        st.sidebar.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        stats = self.data_manager.get_data_statistics()
        st.sidebar.metric("æ³¨å†Œä¸“å®¶æ•°", stats["total_experts"])
        st.sidebar.metric("æ´»è·ƒä¸“å®¶", stats["active_experts"])
        st.sidebar.metric("åˆ†æä¼šè¯", stats["analysis_sessions"])

        if st.sidebar.button("åˆ·æ–°æ•°æ®"):
            st.rerun()

        # æ·»åŠ å†å²æ•°æ®æŸ¥çœ‹å™¨
        self.show_historical_data_viewer()

    def format_scale_label(self, scale):
        """æ ¼å¼åŒ–æ ‡åº¦æ ‡ç­¾ï¼Œæ˜¾ç¤ºåˆ†æ•°å½¢å¼"""
        if scale < 1:
            return f"1/{int(1 / scale)} - {self.scale_meanings[scale]}"
        else:
            return f"{int(scale)} - {self.scale_meanings[scale]}"

    def create_pairwise_comparison_interface(self, criteria: List[str], level: str):
        """åˆ›å»ºä¸¤ä¸¤æ¯”è¾ƒæ‰“åˆ†ç•Œé¢"""
        st.header(f"ğŸ“ {level}ä¸¤ä¸¤æ¯”è¾ƒæ‰“åˆ†")

        # æ£€æŸ¥æ˜¯å¦æœ‰å†å²æ•°æ®
        historical_matrix = None
        has_historical_data = False
        if st.session_state.current_expert_id:
            expert_data = self.data_manager.load_data()
            expert_info = expert_data["experts"].get(st.session_state.current_expert_id, {})
            if level in expert_info.get("judgment_matrices", {}):
                historical_matrix = np.array(expert_info["judgment_matrices"][level]["matrix"])
                has_historical_data = True
                st.success(
                    f"ğŸ“‹ å·²åŠ è½½æ‚¨çš„å†å²æ‰“åˆ†æ•°æ® (ä¿å­˜æ—¶é—´: {expert_info['judgment_matrices'][level]['saved_time'][:19]})")

        st.info(f"è¯·å¯¹ä»¥ä¸‹{len(criteria)}ä¸ªæŒ‡æ ‡è¿›è¡Œä¸¤ä¸¤æ¯”è¾ƒï¼Œé€‰æ‹©ç›¸å¯¹é‡è¦æ€§")

        # æ˜¾ç¤ºAHPæ ‡åº¦è¯´æ˜ï¼ˆåŒ…å«å€’æ•°å…³ç³»ï¼‰
        with st.expander("ğŸ“Š AHPæ ‡åº¦è¯´æ˜ï¼ˆåŒ…å«å€’æ•°å…³ç³»ï¼‰"):
            st.markdown("""
            ### AHPæ ‡åº¦å«ä¹‰ï¼ˆ1-5æ ‡åº¦æ³•ï¼‰

            **é‡è¦ç¨‹åº¦æ ‡åº¦**:
            - **1**: ä¸¤ä¸ªå› ç´ åŒç­‰é‡è¦
            - **2**: ä¸€ä¸ªå› ç´ æ¯”å¦ä¸€ä¸ªç¨å¾®é‡è¦  
            - **3**: ä¸€ä¸ªå› ç´ æ¯”å¦ä¸€ä¸ªæ˜æ˜¾é‡è¦
            - **4**: ä¸€ä¸ªå› ç´ æ¯”å¦ä¸€ä¸ªå¼ºçƒˆé‡è¦
            - **5**: ä¸€ä¸ªå› ç´ æ¯”å¦ä¸€ä¸ªæç«¯é‡è¦

            **å€’æ•°å…³ç³»**:
            - **1/2**: ç¨å¾®ä¸é‡è¦ï¼ˆ2çš„å€’æ•°ï¼‰
            - **1/3**: æ˜æ˜¾ä¸é‡è¦ï¼ˆ3çš„å€’æ•°ï¼‰
            - **1/4**: å¼ºçƒˆä¸é‡è¦ï¼ˆ4çš„å€’æ•°ï¼‰ 
            - **1/5**: æç«¯ä¸é‡è¦ï¼ˆ5çš„å€’æ•°ï¼‰
            """)

        # åˆå§‹åŒ–åˆ¤æ–­çŸ©é˜µ
        n = len(criteria)
        judgment_matrix = np.eye(n)  # åˆå§‹åŒ–ä¸ºå•ä½çŸ©é˜µ

        # åˆ›å»ºæ¯”è¾ƒè¡¨æ ¼
        st.subheader("ä¸¤ä¸¤æ¯”è¾ƒçŸ©é˜µ")
        st.info("è¯·é€‰æ‹©å·¦è¾¹æŒ‡æ ‡ç›¸å¯¹äºå³è¾¹æŒ‡æ ‡çš„é‡è¦æ€§ç¨‹åº¦")

        # ä½¿ç”¨åˆ—å¸ƒå±€åˆ›å»ºæ¯”è¾ƒç•Œé¢
        comparisons = []
        for i in range(n):
            for j in range(i + 1, n):
                comparisons.append((i, j, criteria[i], criteria[j]))

        # åˆ†ç»„æ˜¾ç¤ºæ¯”è¾ƒé¡¹ï¼Œé¿å…ç•Œé¢è¿‡é•¿
        cols_per_row = 2
        for idx in range(0, len(comparisons), cols_per_row):
            cols = st.columns(cols_per_row)
            for col_idx, col in enumerate(cols):
                if idx + col_idx < len(comparisons):
                    i, j, crit1, crit2 = comparisons[idx + col_idx]

                    with col:
                        # åˆ›å»ºå¯¹æ¯”å¡ç‰‡
                        st.markdown(f"**{crit1}** ğŸ†š **{crit2}**")

                        # è®¾ç½®é»˜è®¤å€¼ä¸ºå†å²æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        default_value = 1
                        if has_historical_data:
                            historical_value = historical_matrix[i, j]
                            # æ‰¾åˆ°æœ€æ¥è¿‘çš„æ»‘å—é€‰é¡¹
                            default_value = min(self.ahp_scales, key=lambda x: abs(x - historical_value))

                        # ä½¿ç”¨é€‰æ‹©æ»‘å—
                        importance = st.select_slider(
                            f"é€‰æ‹© {crit1} ç›¸å¯¹äº {crit2} çš„é‡è¦æ€§",
                            options=self.ahp_scales,
                            value=default_value,  # ä½¿ç”¨åŒ¹é…åçš„å†å²æ•°æ®
                            format_func=self.format_scale_label,
                            key=f"comp_{level}_{i}_{j}_{st.session_state.current_expert_id}"
                        )

                        # æ˜¾ç¤ºé€‰æ‹©çš„å«ä¹‰å’Œå¯¹åº”çš„å€’æ•°å…³ç³»
                        if importance > 1:
                            st.success(f"**é€‰æ‹©**: {crit1} æ¯” {crit2} {self.scale_meanings[importance]}")
                            st.info(f"**å¯¹åº”**: {crit2} æ¯” {crit1} {self.scale_meanings[1 / importance]}")
                        elif importance < 1:
                            st.warning(f"**é€‰æ‹©**: {crit1} æ¯” {crit2} {self.scale_meanings[importance]}")
                            st.info(f"**å¯¹åº”**: {crit2} æ¯” {crit1} {self.scale_meanings[1 / importance]}")
                        else:
                            st.info(f"**é€‰æ‹©**: {crit1} å’Œ {crit2} åŒç­‰é‡è¦")

                        judgment_matrix[i, j] = importance
                        judgment_matrix[j, i] = 1 / importance  # è‡ªåŠ¨è®¾ç½®å€’æ•°å…³ç³»

        # æ˜¾ç¤ºå®Œæ•´çš„åˆ¤æ–­çŸ©é˜µé¢„è§ˆ
        st.subheader("ğŸ” åˆ¤æ–­çŸ©é˜µé¢„è§ˆ")

        # åˆ›å»ºæ˜¾ç¤ºç”¨çš„æ•°æ®æ¡†
        display_matrix = pd.DataFrame(
            judgment_matrix,
            index=[f"{i + 1}. {crit}" for i, crit in enumerate(criteria)],
            columns=[f"{i + 1}. {crit}" for i, crit in enumerate(criteria)]
        )

        # æ ¼å¼åŒ–æ˜¾ç¤ºï¼Œä½¿çŸ©é˜µæ›´æ˜“è¯»
        def format_matrix_value(x):
            if x == 1:
                return "1"
            elif x > 1:
                return f"{x:.0f}"
            else:
                return f"1/{int(1 / x)}"

        styled_matrix = display_matrix.copy()
        for col in styled_matrix.columns:
            styled_matrix[col] = styled_matrix[col].apply(format_matrix_value)

        st.dataframe(styled_matrix, use_container_width=True)

        # å¦‚æœæœ‰å†å²æ•°æ®ï¼Œæ˜¾ç¤ºå¯¹æ¯”é€‰é¡¹
        if has_historical_data:
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ æ¢å¤åˆ°å†å²æ•°æ®"):
                    # é‡æ–°åŠ è½½å†å²æ•°æ®åˆ°å½“å‰çŸ©é˜µ
                    judgment_matrix = historical_matrix.copy()
                    st.rerun()
            with col2:
                if st.button("ğŸ”„ é‡æ–°åŠ è½½ç•Œé¢"):
                    st.rerun()

        return judgment_matrix

    def calculate_weights_and_consistency(self, judgment_matrix: np.ndarray) -> Tuple[np.ndarray, float, float]:
        """è®¡ç®—æƒé‡å’Œä¸€è‡´æ€§æŒ‡æ ‡"""
        n = judgment_matrix.shape[0]

        # è®¡ç®—ç‰¹å¾å‘é‡ï¼ˆå‡ ä½•å¹³å‡æ³•ï¼‰
        row_products = np.prod(judgment_matrix, axis=1)
        geometric_means = np.power(row_products, 1 / n)
        weights = geometric_means / np.sum(geometric_means)

        # è®¡ç®—æœ€å¤§ç‰¹å¾å€¼
        weighted_sum = np.dot(judgment_matrix, weights)
        lambda_max = np.sum(weighted_sum / weights) / n

        # è®¡ç®—ä¸€è‡´æ€§æŒ‡æ ‡
        ci = (lambda_max - n) / (n - 1) if n > 1 else 0
        ri = self.ri_values.get(n, 1.45)
        cr = ci / ri if ri > 0 else 0

        return weights, cr, lambda_max

    def check_and_display_consistency(self, judgment_matrix: np.ndarray, level: str):
        """æ£€æŸ¥å¹¶æ˜¾ç¤ºä¸€è‡´æ€§ç»“æœ"""
        weights, cr, lambda_max = self.calculate_weights_and_consistency(judgment_matrix)

        # æ˜¾ç¤ºä¸€è‡´æ€§ç»“æœ
        st.subheader("âœ… ä¸€è‡´æ€§æ£€éªŒç»“æœ")

        col1, col2, col3 = st.columns(3)
        col1.metric("ä¸€è‡´æ€§æ¯”ç‡ (CR)", f"{cr:.4f}")
        col2.metric("æœ€å¤§ç‰¹å¾å€¼", f"{lambda_max:.4f}")

        if cr < 0.1:
            col3.metric("æ£€éªŒç»“æœ", "é€šè¿‡", delta="ä¼˜ç§€")
            st.success("âœ… ä¸€è‡´æ€§æ£€éªŒé€šè¿‡ï¼åˆ¤æ–­çŸ©é˜µå…·æœ‰æ»¡æ„çš„ä¸€è‡´æ€§ã€‚")
        elif cr < 0.2:
            col3.metric("æ£€éªŒç»“æœ", "å¯æ¥å—", delta="ä¸€èˆ¬")
            st.warning("âš ï¸ ä¸€è‡´æ€§å¯æ¥å—ï¼Œä½†å»ºè®®æ£€æŸ¥åˆ¤æ–­æ˜¯å¦åˆç†ã€‚")
        else:
            col3.metric("æ£€éªŒç»“æœ", "ä¸é€šè¿‡", delta="éœ€ä¿®æ­£", delta_color="inverse")
            st.error("âŒ ä¸€è‡´æ€§æ£€éªŒæœªé€šè¿‡ï¼è¯·é‡æ–°è°ƒæ•´åˆ¤æ–­çŸ©é˜µã€‚")

        # æ˜¾ç¤ºæƒé‡ç»“æœ
        st.subheader("ğŸ“Š æƒé‡è®¡ç®—ç»“æœ")
        criteria = self.evaluation_system[level] if level == "ä¸€çº§æŒ‡æ ‡" else self.evaluation_system["äºŒçº§æŒ‡æ ‡"][level]

        weight_data = []
        for i, criterion in enumerate(criteria):
            weight_data.append({
                'æŒ‡æ ‡': criterion,
                'æƒé‡': weights[i],
                'æƒé‡ç™¾åˆ†æ¯”': f"{weights[i] * 100:.2f}%"
            })

        weight_df = pd.DataFrame(weight_data)
        weight_df = weight_df.sort_values('æƒé‡', ascending=False)
        st.dataframe(weight_df, use_container_width=True)

        # å¯è§†åŒ–æƒé‡åˆ†å¸ƒ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # æŸ±çŠ¶å›¾
        bars = ax1.bar(range(len(weights)), weights, color='lightblue', alpha=0.7)
        ax1.set_xlabel('æŒ‡æ ‡')
        ax1.set_ylabel('æƒé‡')
        ax1.set_title(f'{level}æƒé‡åˆ†å¸ƒ')
        ax1.set_xticks(range(len(weights)))
        ax1.set_xticklabels([c[:10] + "..." if len(c) > 10 else c for c in criteria], rotation=45, ha='right')

        for bar, weight in zip(bars, weights):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                     f'{weight:.3f}', ha='center', va='bottom')

        # é¥¼å›¾
        ax2.pie(weights, labels=criteria, autopct='%1.1f%%', startangle=90)
        ax2.set_title(f'{level}æƒé‡æ¯”ä¾‹')

        plt.tight_layout()
        st.pyplot(fig)

        return weights, cr

    def save_expert_judgment(self, level: str, judgment_matrix: np.ndarray, weights: np.ndarray, cr: float):
        """ä¿å­˜ä¸“å®¶åˆ¤æ–­ç»“æœ"""
        if st.session_state.current_expert_id:
            success = self.data_manager.update_expert_judgment(
                st.session_state.current_expert_id, level, judgment_matrix, weights, cr
            )
            if success:
                st.success("âœ… ä¸“å®¶åˆ¤æ–­æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")
            else:
                st.error("âŒ ä¿å­˜ä¸“å®¶åˆ¤æ–­æ•°æ®å¤±è´¥")

    def perform_comprehensive_analysis(self, level: str):
        """æ‰§è¡Œç»¼åˆæ€§ç¾¤ç»„åˆ†æ"""
        st.header("ğŸ‘¥ ä¸“å®¶ç¾¤ç»„ç»¼åˆåˆ†æ")

        # è·å–æ‰€æœ‰ä¸“å®¶çš„åˆ¤æ–­æ•°æ®
        expert_judgments = self.data_manager.get_expert_judgments(level)

        if len(expert_judgments) < 2:
            st.warning(f"éœ€è¦è‡³å°‘2ä½ä¸“å®¶å®Œæˆ{level}çš„æ‰“åˆ†æ‰èƒ½è¿›è¡Œç¾¤ç»„åˆ†æ")
            st.info(f"å½“å‰å®Œæˆ{level}æ‰“åˆ†çš„ä¸“å®¶æ•°: {len(expert_judgments)}")
            return None

        # ç­›é€‰ä¸€è‡´æ€§å¯æ¥å—çš„ä¸“å®¶
        valid_judgments = {k: v for k, v in expert_judgments.items() if v["cr"] < 0.2}

        if len(valid_judgments) < 2:
            st.error(f"éœ€è¦è‡³å°‘2ä½ä¸“å®¶çš„ä¸€è‡´æ€§æ£€éªŒé€šè¿‡æ‰èƒ½è¿›è¡Œç¾¤ç»„åˆ†æ")
            st.info(f"å½“å‰ä¸€è‡´æ€§å¯æ¥å—çš„ä¸“å®¶æ•°: {len(valid_judgments)}")
            return None

        st.success(f"âœ… æ‰¾åˆ°{len(valid_judgments)}ä½ä¸“å®¶çš„æœ‰æ•ˆåˆ¤æ–­æ•°æ®è¿›è¡Œç¾¤ç»„åˆ†æ")

        # è®¡ç®—ç¾¤ç»„æƒé‡ï¼ˆå‡ ä½•å¹³å‡ï¼‰
        all_weights = np.array([result["weights"] for result in valid_judgments.values()])
        group_weights = np.exp(np.mean(np.log(all_weights), axis=0))
        group_weights = group_weights / np.sum(group_weights)  # å½’ä¸€åŒ–

        # æ˜¾ç¤ºç¾¤ç»„åˆ†æç»“æœ
        st.subheader("ğŸ“ˆ ç¾¤ç»„æƒé‡ç»“æœ")

        criteria = self.evaluation_system[level] if level == "ä¸€çº§æŒ‡æ ‡" else self.evaluation_system["äºŒçº§æŒ‡æ ‡"][level]

        # æƒé‡è¡¨æ ¼
        weight_data = []
        for i, criterion in enumerate(criteria):
            individual_weights = [result["weights"][i] for result in valid_judgments.values()]
            std_dev = np.std(individual_weights)

            weight_data.append({
                'æŒ‡æ ‡': criterion,
                'ç¾¤ç»„æƒé‡': group_weights[i],
                'æƒé‡ç™¾åˆ†æ¯”': f"{group_weights[i] * 100:.2f}%",
                'æ ‡å‡†å·®': f"{std_dev:.4f}",
                'å˜å¼‚ç³»æ•°': f"{(std_dev / group_weights[i]):.2%}" if group_weights[i] > 0 else "N/A",
                'ä¸“å®¶æ„è§èŒƒå›´': f"{min(individual_weights):.3f} - {max(individual_weights):.3f}"
            })

        weight_df = pd.DataFrame(weight_data)
        weight_df = weight_df.sort_values('ç¾¤ç»„æƒé‡', ascending=False)
        st.dataframe(weight_df, use_container_width=True)

        # ä¸“å®¶ä¸€è‡´æ€§åˆ†æ
        st.subheader("ğŸ“Š ä¸“å®¶ä¸€è‡´æ€§åˆ†æ")

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # 1. æƒé‡åˆ†å¸ƒç®±çº¿å›¾
        weight_data_for_plot = pd.DataFrame({
            criterion: [result["weights"][i] for result in valid_judgments.values()]
            for i, criterion in enumerate(criteria)
        })

        sns.boxplot(data=weight_data_for_plot, ax=axes[0, 0])
        axes[0, 0].set_title('å„æŒ‡æ ‡æƒé‡ä¸“å®¶åˆ†å¸ƒ')
        axes[0, 0].set_ylabel('æƒé‡')
        axes[0, 0].tick_params(axis='x', rotation=45)

        # 2. ä¸€è‡´æ€§æ¯”ç‡åˆ†å¸ƒ
        cr_values = [result["cr"] for result in valid_judgments.values()]
        expert_names = [result["expert_info"]["name"] for result in valid_judgments.values()]

        colors = ['green' if cr < 0.1 else 'orange' for cr in cr_values]
        bars = axes[0, 1].bar(expert_names, cr_values, color=colors, alpha=0.7)
        axes[0, 1].axhline(y=0.1, color='red', linestyle='--', label='ä¼˜ç§€æ ‡å‡† (CR<0.1)')
        axes[0, 1].axhline(y=0.2, color='orange', linestyle='--', label='å¯æ¥å—æ ‡å‡† (CR<0.2)')
        axes[0, 1].set_title('ä¸“å®¶ä¸€è‡´æ€§æ¯”ç‡åˆ†å¸ƒ')
        axes[0, 1].set_ylabel('ä¸€è‡´æ€§æ¯”ç‡ (CR)')
        axes[0, 1].legend()
        axes[0, 1].tick_params(axis='x', rotation=45)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, cr in zip(bars, cr_values):
            height = bar.get_height()
            axes[0, 1].text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                            f'{cr:.3f}', ha='center', va='bottom')

        # 3. ä¸“å®¶æƒé‡çƒ­å›¾
        weight_matrix = np.array([result["weights"] for result in valid_judgments.values()])
        im = axes[1, 0].imshow(weight_matrix, cmap='YlOrRd', aspect='auto')
        axes[1, 0].set_title('ä¸“å®¶æƒé‡çƒ­å›¾')
        axes[1, 0].set_xlabel('æŒ‡æ ‡')
        axes[1, 0].set_ylabel('ä¸“å®¶')
        axes[1, 0].set_xticks(range(len(criteria)))
        axes[1, 0].set_xticklabels([f"{i + 1}" for i in range(len(criteria))])
        axes[1, 0].set_yticks(range(len(expert_names)))
        axes[1, 0].set_yticklabels([name[:8] + "..." if len(name) > 8 else name for name in expert_names])
        plt.colorbar(im, ax=axes[1, 0])

        # 4. ä¸“å®¶å…±è¯†åº¦æ•£ç‚¹å›¾
        avg_weights_per_expert = np.mean(weight_matrix, axis=1)
        axes[1, 1].scatter(avg_weights_per_expert, cr_values, alpha=0.6)
        for i, (name, avg_w, cr_val) in enumerate(zip(expert_names, avg_weights_per_expert, cr_values)):
            axes[1, 1].annotate(name[:6], (avg_w, cr_val), xytext=(5, 5), textcoords='offset points', fontsize=8)
        axes[1, 1].set_xlabel('å¹³å‡æƒé‡')
        axes[1, 1].set_ylabel('ä¸€è‡´æ€§æ¯”ç‡')
        axes[1, 1].set_title('ä¸“å®¶æƒé‡ä¸ä¸€è‡´æ€§å…³ç³»')
        axes[1, 1].axhline(y=0.1, color='red', linestyle='--', alpha=0.5)
        axes[1, 1].axhline(y=0.2, color='orange', linestyle='--', alpha=0.5)

        plt.tight_layout()
        st.pyplot(fig)

        # ä¸“å®¶å…±è¯†åº¦ç»Ÿè®¡åˆ†æ
        st.subheader("ğŸ¤ ä¸“å®¶å…±è¯†åº¦ç»Ÿè®¡åˆ†æ")

        # è®¡ç®—ä¸“å®¶é—´æƒé‡ç›¸å…³æ€§
        weight_correlations = []
        expert_pairs = []

        for i in range(len(valid_judgments)):
            for j in range(i + 1, len(valid_judgments)):
                corr = np.corrcoef(
                    list(valid_judgments.values())[i]["weights"],
                    list(valid_judgments.values())[j]["weights"]
                )[0, 1]
                weight_correlations.append(corr)
                expert_pairs.append((
                    list(valid_judgments.values())[i]["expert_info"]["name"],
                    list(valid_judgments.values())[j]["expert_info"]["name"]
                ))

        avg_correlation = np.mean(weight_correlations) if weight_correlations else 0

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("å‚ä¸ä¸“å®¶æ•°", len(valid_judgments))
        col2.metric("å¹³å‡ä¸€è‡´æ€§", f"{np.mean(cr_values):.3f}")
        col3.metric("ä¸“å®¶å…±è¯†åº¦", f"{avg_correlation:.3f}")
        col4.metric("æƒé‡ç¨³å®šæ€§", f"{1 - np.mean(weight_df['å˜å¼‚ç³»æ•°'].str.rstrip('%').astype(float) / 100):.3f}")

        # æ˜¾ç¤ºä¸“å®¶å¯¹ç›¸å…³æ€§
        if len(expert_pairs) <= 10:  # é¿å…æ˜¾ç¤ºè¿‡å¤šå¯¹
            st.write("**ä¸“å®¶å¯¹ç›¸å…³æ€§:**")
            pair_data = []
            for (exp1, exp2), corr in zip(expert_pairs, weight_correlations):
                pair_data.append({
                    'ä¸“å®¶å¯¹': f"{exp1} - {exp2}",
                    'ç›¸å…³æ€§': f"{corr:.3f}",
                    'å…±è¯†æ°´å¹³': "é«˜" if corr > 0.8 else "ä¸­" if corr > 0.6 else "ä½"
                })
            st.dataframe(pd.DataFrame(pair_data))

        if avg_correlation > 0.8:
            st.success("âœ… ä¸“å®¶å…±è¯†åº¦å¾ˆé«˜ï¼Œæƒé‡ç»“æœéå¸¸å¯é ")
        elif avg_correlation > 0.6:
            st.warning("âš ï¸ ä¸“å®¶å…±è¯†åº¦ä¸€èˆ¬ï¼Œå»ºè®®è¿›ä¸€æ­¥è®¨è®º")
        else:
            st.error("âŒ ä¸“å®¶å…±è¯†åº¦è¾ƒä½ï¼Œå»ºè®®é‡æ–°è¯„ä¼°æˆ–å¢åŠ ä¸“å®¶æ•°é‡")

        # è¿”å›åˆ†æè¯¦æƒ…
        analysis_details = {
            "expert_count": len(valid_judgments),
            "average_consistency": float(np.mean(cr_values)),
            "consensus_level": float(avg_correlation),
            "weight_stability": float(1 - np.mean(weight_df['å˜å¼‚ç³»æ•°'].str.rstrip('%').astype(float) / 100)),
            "expert_names": [exp["expert_info"]["name"] for exp in valid_judgments.values()]
        }

        return group_weights, analysis_details

    def create_analysis_session(self):
        """åˆ›å»ºåˆ†æä¼šè¯"""
        st.sidebar.header("ğŸ’¾ åˆ†æä¼šè¯")

        with st.sidebar.form("analysis_session"):
            session_name = st.text_input("ä¼šè¯åç§°", "äººå·¥æ™ºèƒ½ç´ å…»æƒé‡åˆ†æ")
            description = st.text_area("æè¿°", "å¤šä½ä¸“å®¶å¯¹äººå·¥æ™ºèƒ½ç´ å…»æŒ‡æ ‡æƒé‡çš„ç»¼åˆåˆ†æ")

            if st.form_submit_button("åˆ›å»ºåˆ†æä¼šè¯"):
                session_id = self.data_manager.create_analysis_session(
                    session_name, description, ["ä¸€çº§æŒ‡æ ‡", "äºŒçº§æŒ‡æ ‡"]
                )
                if session_id:
                    st.session_state.current_session_id = session_id
                    st.sidebar.success(f"åˆ†æä¼šè¯åˆ›å»ºæˆåŠŸ: {session_id}")
                else:
                    st.sidebar.error("åˆ›å»ºåˆ†æä¼šè¯å¤±è´¥")

        if st.session_state.current_session_id:
            st.sidebar.info(f"å½“å‰ä¼šè¯: {st.session_state.current_session_id}")

    def export_comprehensive_results(self):
        """å¯¼å‡ºç»¼åˆåˆ†æç»“æœ"""
        st.header("ğŸ“¥ ç»¼åˆåˆ†æç»“æœå¯¼å‡º")

        if not st.session_state.current_session_id:
            st.warning("è¯·å…ˆåˆ›å»ºåˆ†æä¼šè¯")
            return

        # æ”¶é›†å„å±‚æ¬¡çš„åˆ†æç»“æœ
        level_weights = {}
        analysis_details = {}

        # ä¸€çº§æŒ‡æ ‡åˆ†æ
        level1_result = self.perform_comprehensive_analysis("ä¸€çº§æŒ‡æ ‡")
        if level1_result:
            level_weights["ä¸€çº§æŒ‡æ ‡"], analysis_details["ä¸€çº§æŒ‡æ ‡"] = level1_result

        # äºŒçº§æŒ‡æ ‡åˆ†æ
        for first_level in self.evaluation_system["äºŒçº§æŒ‡æ ‡"].keys():
            level2_result = self.perform_comprehensive_analysis(first_level)
            if level2_result:
                level_weights[first_level], analysis_details[first_level] = level2_result

        if not level_weights:
            st.error("æ²¡æœ‰å¯å¯¼å‡ºçš„æœ‰æ•ˆåˆ†æç»“æœ")
            return

        # æ„å»ºå®Œæ•´çš„æƒé‡ä½“ç³»
        st.subheader("ğŸ† å®Œæ•´çš„äººå·¥æ™ºèƒ½ç´ å…»æƒé‡ä½“ç³»")

        hierarchy_data = []

        if "ä¸€çº§æŒ‡æ ‡" in level_weights:
            level1_weights = level_weights["ä¸€çº§æŒ‡æ ‡"]
            level1_criteria = self.evaluation_system["ä¸€çº§æŒ‡æ ‡"]

            for i, criterion in enumerate(level1_criteria):
                # ä¸€çº§æŒ‡æ ‡
                level1_weight = level1_weights[i]
                hierarchy_data.append({
                    'å±‚çº§': 'ä¸€çº§æŒ‡æ ‡',
                    'æŒ‡æ ‡ç¼–ç ': criterion.split(':')[0],
                    'æŒ‡æ ‡åç§°': criterion.split(':')[1],
                    'ç»å¯¹æƒé‡': level1_weight,
                    'ç›¸å¯¹æƒé‡': '100%',
                    'è¯´æ˜': 'æ ¸å¿ƒèƒ½åŠ›ç»´åº¦'
                })

                # äºŒçº§æŒ‡æ ‡
                if criterion in level_weights:
                    level2_weights = level_weights[criterion]
                    level2_criteria = self.evaluation_system["äºŒçº§æŒ‡æ ‡"][criterion]

                    for j, level2_criterion in enumerate(level2_criteria):
                        absolute_weight = level1_weight * level2_weights[j]
                        hierarchy_data.append({
                            'å±‚çº§': 'äºŒçº§æŒ‡æ ‡',
                            'æŒ‡æ ‡ç¼–ç ': level2_criterion.split(':')[0],
                            'æŒ‡æ ‡åç§°': level2_criterion.split(':')[1],
                            'ç»å¯¹æƒé‡': absolute_weight,
                            'ç›¸å¯¹æƒé‡': f"{level2_weights[j] * 100:.1f}%",
                            'è¯´æ˜': f"{criterion}çš„å…·ä½“è¡¨ç°"
                        })

        hierarchy_df = pd.DataFrame(hierarchy_data)
        st.dataframe(hierarchy_df, use_container_width=True)

        # å¯¼å‡ºæ•°æ®
        st.subheader("ğŸ’¾ æ•°æ®å¯¼å‡º")

        export_data = {
            "system_name": "å¤§å­¦ç”Ÿäººå·¥æ™ºèƒ½ç´ å…»è¯„ä»·ä½“ç³»",
            "analysis_time": datetime.now().isoformat(),
            "session_id": st.session_state.current_session_id,
            "expert_count": self.data_manager.get_data_statistics()["total_experts"],
            "level_weights": {},
            "analysis_quality": analysis_details,
            "hierarchy_weights": hierarchy_data
        }

        for level, weights in level_weights.items():
            if level == "ä¸€çº§æŒ‡æ ‡":
                criteria = self.evaluation_system[level]
            else:
                criteria = self.evaluation_system["äºŒçº§æŒ‡æ ‡"][level]

            export_data["level_weights"][level] = {
                "criteria": criteria,
                "weights": weights.tolist() if hasattr(weights, 'tolist') else weights
            }

        # æ˜¾ç¤ºJSONæ ¼å¼
        with st.expander("æŸ¥çœ‹JSONæ•°æ®"):
            st.json(export_data)

        # æä¾›ä¸‹è½½æŒ‰é’®
        json_str = json.dumps(export_data, ensure_ascii=False, indent=2)
        st.download_button(
            label="ä¸‹è½½å®Œæ•´æƒé‡JSONæ–‡ä»¶",
            data=json_str,
            file_name=f"äººå·¥æ™ºèƒ½ç´ å…»æƒé‡åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
            mime="application/json"
        )

        # ä¿å­˜åˆ°åˆ†æä¼šè¯
        for level, weights in level_weights.items():
            self.data_manager.save_analysis_results(
                st.session_state.current_session_id,
                level,
                weights,
                analysis_details.get(level, {})
            )

        st.success("âœ… åˆ†æç»“æœå·²ä¿å­˜å¹¶å¯¼å‡º")


def main():
    """ä¸»åº”ç”¨"""
    # åˆå§‹åŒ–ç³»ç»Ÿ
    ahp_system = AHPExpertScoringSystem()
    ahp_system.initialize_session_state()

    # ä¾§è¾¹æ 
    st.sidebar.title("ğŸ”§ ç³»ç»Ÿæ§åˆ¶")

    # ä¸“å®¶æ³¨å†Œå’Œç®¡ç†
    ahp_system.create_expert_registration()
    ahp_system.show_expert_management()
    ahp_system.create_analysis_session()

    # ä¸»å†…å®¹åŒº
    if not st.session_state.current_expert_id:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§æ æ³¨å†Œä¸“å®¶èº«ä»½å¼€å§‹æ‰“åˆ†")

        # æ˜¾ç¤ºç³»ç»Ÿæ¦‚è§ˆ
        st.header("ğŸ“ˆ ç³»ç»Ÿæ¦‚è§ˆ")
        stats = ahp_system.data_manager.get_data_statistics()

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("æ€»ä¸“å®¶æ•°", stats["total_experts"])
        col2.metric("æ´»è·ƒä¸“å®¶", stats["active_experts"])
        col3.metric("åˆ†æä¼šè¯", stats["analysis_sessions"])
        col4.metric("æœ€åæ›´æ–°", stats["last_modified"][:10])

        # æ˜¾ç¤ºå„å±‚æ¬¡å®Œæˆæƒ…å†µ
        st.subheader("å„å±‚æ¬¡åˆ†æå®Œæˆæƒ…å†µ")
        level_stats = stats["level_completion"]

        level_data = []
        for level, stats in level_stats.items():
            level_data.append({
                "åˆ†æå±‚æ¬¡": level,
                "å®Œæˆä¸“å®¶æ•°": stats["completed_experts"],
                "æœ‰æ•ˆåˆ¤æ–­æ•°": stats["acceptable_judgments"],
                "å®Œæˆç‡": f"{(stats['completed_experts'] / max(1, level_stats['ä¸€çº§æŒ‡æ ‡']['completed_experts'])) * 100:.1f}%"
            })

        st.dataframe(pd.DataFrame(level_data))
        return

    # åˆ†æå±‚æ¬¡é€‰æ‹©
    st.sidebar.header("ğŸ“Š åˆ†æè®¾ç½®")
    analysis_level = st.sidebar.radio(
        "é€‰æ‹©åˆ†æå±‚æ¬¡",
        ["ä¸“å®¶ä¸ªäººæ‰“åˆ†", "ç¾¤ç»„ä¸€è‡´æ€§åˆ†æ", "å®Œæ•´æƒé‡ä½“ç³»å¯¼å‡º"],
        help="é€‰æ‹©éœ€è¦è¿›è¡Œçš„åˆ†æç±»å‹"
    )

    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºç›¸åº”çš„ç•Œé¢
    if analysis_level == "ä¸“å®¶ä¸ªäººæ‰“åˆ†":
        st.sidebar.header("ğŸ” æ‰“åˆ†å±‚æ¬¡é€‰æ‹©")
        scoring_level = st.sidebar.radio(
            "é€‰æ‹©æ‰“åˆ†å±‚æ¬¡",
            ["ä¸€çº§æŒ‡æ ‡", "äºŒçº§æŒ‡æ ‡"],
            help="é€‰æ‹©è¦è¿›è¡Œæ‰“åˆ†çš„æŒ‡æ ‡å±‚æ¬¡"
        )

        if scoring_level == "ä¸€çº§æŒ‡æ ‡":
            st.session_state.current_level = "ä¸€çº§æŒ‡æ ‡"
            criteria = ahp_system.evaluation_system["ä¸€çº§æŒ‡æ ‡"]

            # æ˜¾ç¤ºä¸€çº§æŒ‡æ ‡è¯´æ˜
            st.header("ğŸ¯ ä¸€çº§æŒ‡æ ‡è¯´æ˜")
            st.markdown("""
            **äººå·¥æ™ºèƒ½ç´ å…»å››å¤§æ ¸å¿ƒç»´åº¦**:
            - **B1: ç³»ç»Ÿæ€§è®¤çŸ¥**: æ„æˆAIç´ å…»çš„å®Œæ•´çŸ¥è¯†æ¡†æ¶ï¼Œæ¶µç›–æ•°æ®ã€ç®—æ³•ã€ç®—åŠ›ç­‰æ ¸å¿ƒè¦ç´ ã€‚
            - **B2: æ„å»ºå¼èƒ½åŠ›**: ä»é—®é¢˜å®šä¹‰åˆ°ç»“æœå‘ˆç°çš„æ ¸å¿ƒæŠ€èƒ½é›†ï¼Œå¼ºè°ƒAIè§£å†³æ–¹æ¡ˆçš„å®Œæ•´æ„å»ºæµç¨‹ã€‚
            - **B3: åˆ›é€ ä¸æ€è¾¨**: ç´ å…»çš„é¡¶å³°ï¼Œå¼ºè°ƒå­¦ç”Ÿçš„è‡ªä¸»æ€§ã€æ‰¹åˆ¤æ€§æ€ç»´å’Œåˆ›é€ æ€§åº”ç”¨AIçš„èƒ½åŠ›ã€‚
            - **B4: äººæœ¬ä¸è´£ä»»**: å…³æ³¨æ•°æ®éšç§ã€ç®—æ³•å…¬å¹³ã€ç¤¾ä¼šä¼¦ç†ç­‰AIå‘å–„çš„æ ¸å¿ƒè´£ä»»ã€‚
            """)

            # æ‰“åˆ†ç•Œé¢ï¼ˆç°åœ¨ä¼šè‡ªåŠ¨åŠ è½½å†å²æ•°æ®ï¼‰
            judgment_matrix = ahp_system.create_pairwise_comparison_interface(criteria, "ä¸€çº§æŒ‡æ ‡")

            if st.button("æäº¤æ‰“åˆ†å¹¶æ£€éªŒä¸€è‡´æ€§", type="primary"):
                weights, cr = ahp_system.check_and_display_consistency(judgment_matrix, "ä¸€çº§æŒ‡æ ‡")
                ahp_system.save_expert_judgment("ä¸€çº§æŒ‡æ ‡", judgment_matrix, weights, cr)

        else:  # äºŒçº§æŒ‡æ ‡
            st.sidebar.header("ğŸ” äºŒçº§æŒ‡æ ‡é€‰æ‹©")
            selected_first_level = st.sidebar.selectbox(
                "é€‰æ‹©ä¸€çº§æŒ‡æ ‡",
                ahp_system.evaluation_system["ä¸€çº§æŒ‡æ ‡"]
            )

            if selected_first_level in ahp_system.evaluation_system["äºŒçº§æŒ‡æ ‡"]:
                criteria = ahp_system.evaluation_system["äºŒçº§æŒ‡æ ‡"][selected_first_level]
                st.session_state.current_level = selected_first_level

                st.header(f"ğŸ” {selected_first_level} - äºŒçº§æŒ‡æ ‡è¯´æ˜")
                st.info(f"è¯·å¯¹{selected_first_level}ä¸‹çš„{len(criteria)}ä¸ªäºŒçº§æŒ‡æ ‡è¿›è¡Œä¸¤ä¸¤æ¯”è¾ƒ")

                # æ‰“åˆ†ç•Œé¢ï¼ˆç°åœ¨ä¼šè‡ªåŠ¨åŠ è½½å†å²æ•°æ®ï¼‰
                judgment_matrix = ahp_system.create_pairwise_comparison_interface(criteria, selected_first_level)

                if st.button("æäº¤æ‰“åˆ†å¹¶æ£€éªŒä¸€è‡´æ€§", type="primary"):
                    weights, cr = ahp_system.check_and_display_consistency(judgment_matrix, selected_first_level)
                    ahp_system.save_expert_judgment(selected_first_level, judgment_matrix, weights, cr)


    elif analysis_level == "ç¾¤ç»„ä¸€è‡´æ€§åˆ†æ":
        st.sidebar.header("ğŸ” åˆ†æå±‚æ¬¡é€‰æ‹©")
        analysis_level_select = st.sidebar.selectbox(
            "é€‰æ‹©åˆ†æå±‚æ¬¡",
            ["ä¸€çº§æŒ‡æ ‡"] + list(ahp_system.evaluation_system["äºŒçº§æŒ‡æ ‡"].keys())
        )

        st.header(f"ğŸ‘¥ {analysis_level_select} - ç¾¤ç»„ä¸€è‡´æ€§åˆ†æ")
        ahp_system.perform_comprehensive_analysis(analysis_level_select)

    else:  # å®Œæ•´æƒé‡ä½“ç³»å¯¼å‡º
        st.header("ğŸ—ï¸ å®Œæ•´æƒé‡ä½“ç³»å¯¼å‡º")
        ahp_system.export_comprehensive_results()

    # ä½¿ç”¨è¯´æ˜
    with st.sidebar.expander("ğŸ’¡ ç³»ç»Ÿä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        **æ•°æ®å­˜å‚¨ç‰¹æ€§**:
        - âœ… ä¸“å®¶æ•°æ®æŒä¹…åŒ–ä¿å­˜
        - âœ… æ”¯æŒå¤šä½ä¸“å®¶ç‹¬ç«‹æ‰“åˆ†
        - âœ… è‡ªåŠ¨ä¸€è‡´æ€§éªŒè¯
        - âœ… ç¾¤ç»„æƒé‡è®¡ç®—
        - âœ… åˆ†æä¼šè¯ç®¡ç†

        **æ“ä½œæµç¨‹**:
        1. ä¸“å®¶æ³¨å†Œä¸ªäººä¿¡æ¯
        2. è¿›è¡Œä¸ªäººå±‚æ¬¡æ‰“åˆ†
        3. ç³»ç»Ÿè‡ªåŠ¨æ£€éªŒä¸€è‡´æ€§
        4. è¿›è¡Œç¾¤ç»„ä¸€è‡´æ€§åˆ†æ
        5. å¯¼å‡ºå®Œæ•´æƒé‡ä½“ç³»

        **æ•°æ®æ–‡ä»¶**: `expert_data.json`
        - æ‰€æœ‰ä¸“å®¶æ•°æ®è‡ªåŠ¨ä¿å­˜
        - æ”¯æŒå…³é—­é¡µé¢åæ•°æ®ä¸ä¸¢å¤±
        - æ”¯æŒå¤šä½ä¸“å®¶åä½œåˆ†æ
        """)


if __name__ == "__main__":
    main()
